{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a086e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# ensures that the graphs are displayed in the notebook along with the code\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "\n",
    "# Import the ZOD DevKit\n",
    "from zod.frames.zod_frames import ZodFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706a8d1f",
   "metadata": {},
   "source": [
    "### Set path to dataset and choose version\n",
    "version $\\in$ {\"mini\", \"full\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/staging/dataset_donation/round_2\"\n",
    "version = \"mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d91b7",
   "metadata": {},
   "source": [
    "### Initialize ZodFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "zod = ZodFrames(dataset_root=data_dir, version=version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7f8f88",
   "metadata": {},
   "source": [
    "### Split into Training and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d2bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = zod.get_split(\"train\")\n",
    "val = zod.get_split(\"val\")\n",
    "print(\"Training split: \", train)\n",
    "print(\"Validation split: \", val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3147caf6",
   "metadata": {},
   "source": [
    "# Data\n",
    "#### This dataset includes data from 3 sensor modalities and calibrations for each sensor:  \n",
    "1. **Camera** - DESCRIPTION OF CAMERAS?\n",
    "2. **LiDAR** - DESCRIPTION OF LIDARS?\n",
    "3. **OXTS** - DESCRIPTION OF OXTS\n",
    "\n",
    "We will in the following cells go through how this data can be fetched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6311337",
   "metadata": {},
   "source": [
    "### Read calibration for all available sensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d09de",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = \"029229\"\n",
    "calib = zod.read_calibration(frame_id)\n",
    "lidar_velodyne_calib = [\"lidar_velodyne\"]\n",
    "camera_front_calib = calib.cameras[\"camera_front\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec04149d",
   "metadata": {},
   "source": [
    "### Visualize single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a85ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = \"029229\"\n",
    "image_path = zod.get_image_path(frame_id)\n",
    "image = plt.imread(image_path)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f78ed",
   "metadata": {},
   "source": [
    "### Visualize single LiDAR point cloud\n",
    " Lidar fields description:\n",
    "\n",
    "| Name | Type | Units | Description |\n",
    "| --- | --- | --- | --- |\n",
    "| 'timestamp' | string |  seconds  | UTC timestamp of each point. |\n",
    "| 'x' | double |  meters  | x coordinate of the point in lidar frame |\n",
    "| 'y' | double |  meters  | y coordinate of the point in lidar frame |\n",
    "| 'z' | double |  meters  | z coordinate of the point in lidar frame |\n",
    "| 'intensity' | double |    | intensity level of each point in range [0..255] |\n",
    "| 'diode_index' | integer |    | index of diode emitter which produced a point (1..128) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ee342",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = zod.read_pointcloud(frame_id, \"lidar_velodyne\", n_sweeps_before=10, n_sweeps_after=0, motion_compensation=True)\n",
    "np.hstack((pcd.points, pcd.intensity[:, None])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize BEV\n",
    "from zod.visualization.lidar_bev import BEVBox\n",
    "\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "box3d = object_annotations\n",
    "\n",
    "bev = BEVBox()\n",
    "bev_image = bev(\n",
    "    np.hstack((pcd.points, pcd.intensity[:, None])),\n",
    "    (\n",
    "        np.array([obj.name for obj in object_annotations if obj.box3d]),\n",
    "        np.concatenate([obj.box3d.center[None,:] for obj in object_annotations if obj.box3d], axis=0),\n",
    "        np.concatenate([obj.box3d.size[None,:] for obj in object_annotations if obj.box3d], axis=0),\n",
    "        [obj.box3d.orientation for obj in object_annotations if obj.box3d],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc95d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize in image\n",
    "from zod.visualization.lidar_on_image import visualize_lidar_on_image\n",
    "\n",
    "lid_image = visualize_lidar_on_image(pcd, calib, image)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(lid_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720ce4aa",
   "metadata": {},
   "source": [
    "### Visualize OXTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.oxts_visualization import plot_gps_track_from_dataset_sequence\n",
    "\n",
    "frame_id = \"029229\"\n",
    "oxts_data = zod.read_oxts(frame_id)\n",
    "\n",
    "# plot GPS track on interactive map\n",
    "plot_gps_track_from_dataset_sequence(oxts_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa628f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.oxts_on_image import visualize_gps_on_image\n",
    "\n",
    "# visualize GPS track over image\n",
    "timestamp = zod.get_timestamp(frame_id)\n",
    "camera_calib = zod.read_calibration(frame_id).cameras[\"camera_front\"]\n",
    "\n",
    "gps_on_image = visualize_gps_on_image(oxts_data, timestamp, camera_calib, image)\n",
    "gps_on_image = cv2.cvtColor(gps_on_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(gps_on_image)\n",
    "plt.title(\"GPS on image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ae408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "601f554c",
   "metadata": {},
   "source": [
    "#### There are 4 types of annotationed objects:  \n",
    "1. **dynamic_objects** - objects that can move (vehicles, pedestrians etc.) - annotated with 2D/3D bounding boxes\n",
    "2. **static_objects** - non-movable objects (light poles, traffic signs etc.) - annotated with 2D/3D bounding boxes\n",
    "3. **lane_markings** - lane markings and road paitings - annotated with polygons\n",
    "4. **ego_road** (Doesn't exist for all frames) - polygons that shows the road where ego vehicle can drive - annotated with polygons "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdac7c47",
   "metadata": {},
   "source": [
    "### Object annotations\n",
    "#### Visualize a single object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.object_visualization import overlay_object_2d_box_on_image\n",
    "\n",
    "frame_id = \"082291\"\n",
    "object_id = 31\n",
    "\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "box2d = object_annotations[object_id].box2d\n",
    "\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "image = overlay_object_2d_box_on_image(image, box2d, color=(255, 0, 0), line_thickness=10)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dde011",
   "metadata": {},
   "source": [
    "#### 3D Bounding boxes can also be visualized in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f457448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.object_visualization import overlay_object_3d_box_on_image\n",
    "\n",
    "frame_id = \"018591\"\n",
    "object_ids = [61, 63, 66, 69, 77]\n",
    "\n",
    "calib = zod.read_calibration(frame_id)\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "\n",
    "for object_id in object_ids:\n",
    "    image = overlay_object_3d_box_on_image(\n",
    "        image, object_annotations[object_id].box3d, calib, color=(255, 0, 0), line_thickness=10\n",
    "    )\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dd078c",
   "metadata": {},
   "source": [
    "#### Visualize all objects (both static and dynamic) in a scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.object_visualization import (\n",
    "    overlay_object_2d_box_on_image,\n",
    "    overlay_object_properties_on_image,\n",
    ")\n",
    "\n",
    "frame_id = \"018591\"\n",
    "\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "\n",
    "text_areas = []\n",
    "for object_index, object_annotation in enumerate(object_annotations):\n",
    "    image = overlay_object_2d_box_on_image(image, object_annotation.box2d)\n",
    "    image = overlay_object_properties_on_image(\n",
    "        image, object_annotation, properties_list=[\"name\"], color=(255, 255, 0), text_areas=[]\n",
    "    )\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1e6dae",
   "metadata": {},
   "source": [
    "#### Visualize only vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c2bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.object_visualization import (\n",
    "    overlay_object_2d_box_on_image,\n",
    "    overlay_object_properties_on_image,\n",
    ")\n",
    "\n",
    "frame_id = \"018591\"\n",
    "\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "\n",
    "for object_index, object_annotation in enumerate(object_annotations):\n",
    "    text_areas = []\n",
    "    if object_annotation.name == \"Vehicle\":\n",
    "        image = overlay_object_2d_box_on_image(image, object_annotation.box2d)\n",
    "        image = overlay_object_properties_on_image(\n",
    "            image,\n",
    "            object_annotation,\n",
    "            properties_list=[\"object_id\"],\n",
    "            color=(255, 255, 0),\n",
    "            object_id=object_index,\n",
    "            text_areas=[],\n",
    "        )\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862dac1e",
   "metadata": {},
   "source": [
    "#### Visualize only pedestrians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e317fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.object_visualization import (\n",
    "    overlay_object_2d_box_on_image,\n",
    "    overlay_object_properties_on_image,\n",
    ")\n",
    "\n",
    "frame_id = \"062592\"\n",
    "\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "\n",
    "for object_index, object_annotation in enumerate(object_annotations):\n",
    "    text_areas = []\n",
    "    if object_annotation.name == \"Pedestrian\":\n",
    "        image = overlay_object_2d_box_on_image(image, object_annotation.box2d)\n",
    "        image = overlay_object_properties_on_image(\n",
    "            image,\n",
    "            object_annotation,\n",
    "            properties_list=[\"object_id\"],\n",
    "            color=(255, 255, 0),\n",
    "            object_id=object_index,\n",
    "            text_areas=[],\n",
    "        )\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c948f7a",
   "metadata": {},
   "source": [
    "#### Visualize only pole objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ad8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.object_visualization import (\n",
    "    overlay_object_2d_box_on_image,\n",
    "    overlay_object_properties_on_image,\n",
    ")\n",
    "\n",
    "frame_id = \"009158\"\n",
    "\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "\n",
    "for object_index, object_annotation in enumerate(object_annotations):\n",
    "    text_areas = []\n",
    "    if object_annotation.name == \"PoleObject\":\n",
    "        image = overlay_object_2d_box_on_image(image, object_annotation.box2d)\n",
    "        image = overlay_object_properties_on_image(\n",
    "            image,\n",
    "            object_annotation,\n",
    "            properties_list=[\"object_type\"],\n",
    "            color=(255, 0, 0),\n",
    "            text_areas=[],\n",
    "        )\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210eb110",
   "metadata": {},
   "source": [
    "#### Visualize only Traffic Signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb62a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.object_visualization import (\n",
    "    overlay_object_2d_box_on_image,\n",
    "    overlay_object_properties_on_image,\n",
    ")\n",
    "\n",
    "frame_id = \"062592\"\n",
    "\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "\n",
    "for object_index, object_annotation in enumerate(object_annotations):\n",
    "    text_areas = []\n",
    "    if object_annotation.name == \"TrafficSign\":\n",
    "        image = overlay_object_2d_box_on_image(image, object_annotation.box2d)\n",
    "        image = overlay_object_properties_on_image(\n",
    "            image,\n",
    "            object_annotation,\n",
    "            properties_list=[\"object_id\"],\n",
    "            color=(255, 0, 0),\n",
    "            text_areas=[],\n",
    "            object_id=object_index,\n",
    "        )\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bcf24e",
   "metadata": {},
   "source": [
    "### Visualize lane marking annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652fb342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.lane_markings_visualization import overlay_lane_markings_on_image\n",
    "\n",
    "frame_id = \"029229\"\n",
    "lane_markings_annotation = zod.read_lane_markings_annotation(frame_id)\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "image = overlay_lane_markings_on_image(lane_markings_annotation, image)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc16dd",
   "metadata": {},
   "source": [
    "### Ego Road annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65006b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.ego_road_visualization import overlay_ego_road_on_image\n",
    "\n",
    "frame_id = \"062592\"\n",
    "ego_road_annotation = zod.read_ego_road_annotation(frame_id)\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "image = overlay_ego_road_on_image(ego_road_annotation, image)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a51f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6a915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59217d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f801d9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('zod-PpJEx3ch-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3c82d7c2bcd51e0f6f560efddbe4947691ffc8d309dccd0d20a4aaa5de9dcbf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
