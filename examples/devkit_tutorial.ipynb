{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb1c4ced",
   "metadata": {},
   "source": [
    "## Development-Kit Tutorial for Zenseact Open Dataset\n",
    "\n",
    "## NOTE THAT THIS IS CURRENTLY BROKEN. WE ARE WORKING ON IT.\n",
    "\n",
    "This notebook aims to give a brief introduction to working with the data loaders and visualization functionalities. \n",
    "\n",
    "Data loaders are provided for camera images, LiDAR point clouds, OXTS (high-precision GPS) vehicle data, sensor calibrations, and multiple annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a086e28",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'zod'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/s0001387/Documents/zod/examples/devkit_tutorial.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/s0001387/Documents/zod/examples/devkit_tutorial.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mrcParams[\u001b[39m\"\u001b[39m\u001b[39mfigure.figsize\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m [\u001b[39m20\u001b[39m, \u001b[39m10\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/s0001387/Documents/zod/examples/devkit_tutorial.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Import the ZOD DevKit\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/s0001387/Documents/zod/examples/devkit_tutorial.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mzod\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mzod_frames\u001b[39;00m \u001b[39mimport\u001b[39;00m ZodFrames\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'zod'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# ensures that the graphs are displayed in the notebook along with the code\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 10]\n",
    "\n",
    "# Import the ZOD DevKit\n",
    "from zod.frames.zod_frames import ZodFrames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "706a8d1f",
   "metadata": {},
   "source": [
    "### Set path to dataset and choose version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6e3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/staging/dataset_donation/round_2\"\n",
    "version = \"mini\"  # \"mini\" or \"full\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d91b7",
   "metadata": {},
   "source": [
    "### Initialize ZodFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "zod = ZodFrames(dataset_root=data_dir, version=version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7f8f88",
   "metadata": {},
   "source": [
    "### Split into Training and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d2bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = zod.get_split(\"train\")\n",
    "val = zod.get_split(\"val\")\n",
    "print(\"Training split: \", train)\n",
    "print(\"Validation split: \", val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3147caf6",
   "metadata": {},
   "source": [
    "# Data\n",
    "#### This dataset includes data from 3 sensor modalities and calibrations for each sensor:  \n",
    "1. **Camera** - Anonymized front camera images.\n",
    "\n",
    "2. **LiDAR** - The LiDAR point cloud is the closest LiDAR scan to the camera timestamp of the core frame. Zenseact Open Dataset also provides a range of LiDAR point clouds captured in [-1s, +1s] at 10Hz around the core frame for the sequences.\n",
    "\n",
    "3. **OXTS** - High-precision GPS. OXTS data is provided in [-1s, ~10s] around the core frames for each sequence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6311337",
   "metadata": {},
   "source": [
    "### Read calibration for available sensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d09de",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = \"029229\"\n",
    "calib = zod.read_calibration(frame_id)\n",
    "lidar_velodyne_calib = [\"lidar_velodyne\"]\n",
    "camera_front_calib = calib.cameras[\"camera_front\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b04c58f",
   "metadata": {},
   "source": [
    "### Read meta data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d3682",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = \"029229\"\n",
    "meta_data = zod.read_meta_data(frame_id)\n",
    "meta_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec04149d",
   "metadata": {},
   "source": [
    "### Visualize single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a85ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = \"029229\"\n",
    "image_path = zod.get_image_path(frame_id)\n",
    "image = plt.imread(image_path)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f78ed",
   "metadata": {},
   "source": [
    "### Visualize single LiDAR point cloud\n",
    " Lidar fields description:\n",
    "\n",
    "| Name | Type | Units | Description |\n",
    "| --- | --- | --- | --- |\n",
    "| 'timestamp' | string |  seconds  | UTC timestamp of each point. |\n",
    "| 'x' | double |  meters  | x coordinate of the point in lidar frame |\n",
    "| 'y' | double |  meters  | y coordinate of the point in lidar frame |\n",
    "| 'z' | double |  meters  | z coordinate of the point in lidar frame |\n",
    "| 'intensity' | double |    | intensity level of each point in range [0..255] |\n",
    "| 'diode_index' | integer |    | index of diode emitter which produced a point (1..128) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ee342",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = zod.read_pointcloud(\n",
    "    frame_id, \"lidar_velodyne\", n_sweeps_before=10, n_sweeps_after=0, motion_compensation=True\n",
    ")\n",
    "np.hstack((pcd.points, pcd.intensity[:, None])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize BEV\n",
    "from zod.visualization.lidar_bev import BEVBox\n",
    "\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "box3d = object_annotations\n",
    "\n",
    "bev = BEVBox()\n",
    "bev_image = bev(\n",
    "    np.hstack((pcd.points, pcd.intensity[:, None])),\n",
    "    (\n",
    "        np.array([obj.name for obj in object_annotations if obj.box3d]),\n",
    "        np.concatenate(\n",
    "            [obj.box3d.center[None, :] for obj in object_annotations if obj.box3d], axis=0\n",
    "        ),\n",
    "        np.concatenate(\n",
    "            [obj.box3d.size[None, :] for obj in object_annotations if obj.box3d], axis=0\n",
    "        ),\n",
    "        [obj.box3d.orientation for obj in object_annotations if obj.box3d],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc95d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize in image\n",
    "from zod.visualization.lidar_on_image import visualize_lidar_on_image\n",
    "\n",
    "lid_image = visualize_lidar_on_image(pcd, calib, image)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(lid_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720ce4aa",
   "metadata": {},
   "source": [
    "### Visualize OXTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.oxts_visualization import plot_gps_track_from_dataset_sequence\n",
    "\n",
    "frame_id = \"029229\"\n",
    "ego_motion = zod.read_ego_motion(frame_id)\n",
    "\n",
    "# plot GPS track on interactive map\n",
    "plot_gps_track_from_dataset_sequence(ego_motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa628f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: fix this\n",
    "if False:\n",
    "    from zod.visualization.oxts_on_image import visualize_gps_on_image\n",
    "    import cv2\n",
    "\n",
    "    # visualize GPS track over image\n",
    "    timestamp = zod.get_timestamp(frame_id)\n",
    "    camera_calib = zod.read_calibration(frame_id).cameras[\"camera_front\"]\n",
    "\n",
    "    gps_on_image = visualize_gps_on_image(ego_motion, timestamp, camera_calib, image)\n",
    "    gps_on_image = cv2.cvtColor(gps_on_image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(gps_on_image)\n",
    "    plt.title(\"GPS on image\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f554c",
   "metadata": {},
   "source": [
    "#### There are 4 types of annotationed objects:  \n",
    "1. **dynamic_objects** - objects that can move (vehicles, pedestrians etc.) - annotated with 2D/3D bounding boxes\n",
    "2. **static_objects** - non-movable objects (light poles, traffic signs etc.) - annotated with 2D/3D bounding boxes\n",
    "3. **lane_markings** - lane markings and road paitings - annotated with polygons\n",
    "4. **ego_road** (Doesn't exist for all frames) - polygons that shows the road where ego vehicle can drive - annotated with polygons "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdac7c47",
   "metadata": {},
   "source": [
    "### Object annotations\n",
    "#### Visualize a single object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.object_visualization import overlay_object_2d_box_on_image\n",
    "\n",
    "frame_id = \"082291\"\n",
    "object_id = 31\n",
    "\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "box2d = object_annotations[object_id].box2d\n",
    "\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "image = overlay_object_2d_box_on_image(image, box2d, color=(255, 0, 0), line_thickness=10)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dde011",
   "metadata": {},
   "source": [
    "#### 3D Bounding boxes can also be visualized in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f457448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.object_visualization import overlay_object_3d_box_on_image\n",
    "\n",
    "frame_id = \"018591\"\n",
    "object_ids = [61, 63, 66, 69, 77]\n",
    "\n",
    "calib = zod.read_calibration(frame_id)\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "\n",
    "for object_id in object_ids:\n",
    "    image = overlay_object_3d_box_on_image(\n",
    "        image, object_annotations[object_id].box3d, calib, color=(255, 0, 0), line_thickness=10\n",
    "    )\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dd078c",
   "metadata": {},
   "source": [
    "#### Visualize all objects (both static and dynamic) in a scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.object_visualization import (\n",
    "    overlay_object_2d_box_on_image,\n",
    "    overlay_object_properties_on_image,\n",
    ")\n",
    "\n",
    "frame_id = \"018591\"\n",
    "\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "\n",
    "text_areas = []\n",
    "for object_index, object_annotation in enumerate(object_annotations):\n",
    "    image = overlay_object_2d_box_on_image(image, object_annotation.box2d)\n",
    "    image = overlay_object_properties_on_image(\n",
    "        image, object_annotation, properties_list=[\"name\"], color=(255, 255, 0), text_areas=[]\n",
    "    )\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1e6dae",
   "metadata": {},
   "source": [
    "#### Visualize only vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c2bfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.object_visualization import (\n",
    "    overlay_object_2d_box_on_image,\n",
    "    overlay_object_properties_on_image,\n",
    ")\n",
    "\n",
    "frame_id = \"018591\"\n",
    "\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "\n",
    "for object_index, object_annotation in enumerate(object_annotations):\n",
    "    text_areas = []\n",
    "    if object_annotation.name == \"Vehicle\":\n",
    "        image = overlay_object_2d_box_on_image(image, object_annotation.box2d)\n",
    "        image = overlay_object_properties_on_image(\n",
    "            image,\n",
    "            object_annotation,\n",
    "            properties_list=[\"object_id\"],\n",
    "            color=(255, 255, 0),\n",
    "            object_id=object_index,\n",
    "            text_areas=[],\n",
    "        )\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862dac1e",
   "metadata": {},
   "source": [
    "#### Visualize only pedestrians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e317fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.object_visualization import (\n",
    "    overlay_object_2d_box_on_image,\n",
    "    overlay_object_properties_on_image,\n",
    ")\n",
    "\n",
    "frame_id = \"062592\"\n",
    "\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "\n",
    "for object_index, object_annotation in enumerate(object_annotations):\n",
    "    text_areas = []\n",
    "    if object_annotation.name == \"Pedestrian\":\n",
    "        image = overlay_object_2d_box_on_image(image, object_annotation.box2d)\n",
    "        image = overlay_object_properties_on_image(\n",
    "            image,\n",
    "            object_annotation,\n",
    "            properties_list=[\"object_id\"],\n",
    "            color=(255, 255, 0),\n",
    "            object_id=object_index,\n",
    "            text_areas=[],\n",
    "        )\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c948f7a",
   "metadata": {},
   "source": [
    "#### Visualize only pole objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ad8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.object_visualization import (\n",
    "    overlay_object_2d_box_on_image,\n",
    "    overlay_object_properties_on_image,\n",
    ")\n",
    "\n",
    "frame_id = \"009158\"\n",
    "\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "\n",
    "for object_index, object_annotation in enumerate(object_annotations):\n",
    "    text_areas = []\n",
    "    if object_annotation.name == \"PoleObject\":\n",
    "        image = overlay_object_2d_box_on_image(image, object_annotation.box2d)\n",
    "        image = overlay_object_properties_on_image(\n",
    "            image,\n",
    "            object_annotation,\n",
    "            properties_list=[\"object_type\"],\n",
    "            color=(255, 0, 0),\n",
    "            text_areas=[],\n",
    "        )\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210eb110",
   "metadata": {},
   "source": [
    "#### Visualize only Traffic Signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb62a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.object_visualization import (\n",
    "    overlay_object_2d_box_on_image,\n",
    "    overlay_object_properties_on_image,\n",
    ")\n",
    "\n",
    "frame_id = \"062592\"\n",
    "\n",
    "object_annotations = zod.read_object_detection_annotation(frame_id)\n",
    "\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "\n",
    "for object_index, object_annotation in enumerate(object_annotations):\n",
    "    text_areas = []\n",
    "    if object_annotation.name == \"TrafficSign\":\n",
    "        image = overlay_object_2d_box_on_image(image, object_annotation.box2d)\n",
    "        image = overlay_object_properties_on_image(\n",
    "            image,\n",
    "            object_annotation,\n",
    "            properties_list=[\"object_id\"],\n",
    "            color=(255, 0, 0),\n",
    "            text_areas=[],\n",
    "            object_id=object_index,\n",
    "        )\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bcf24e",
   "metadata": {},
   "source": [
    "### Visualize lane marking annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652fb342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.lane_markings_visualization import overlay_lane_markings_on_image\n",
    "\n",
    "frame_id = \"029229\"\n",
    "lane_markings_annotation = zod.read_lane_markings_annotation(frame_id)\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "image = overlay_lane_markings_on_image(lane_markings_annotation, image)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc16dd",
   "metadata": {},
   "source": [
    "### Ego Road annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65006b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zod.visualization.ego_road_visualization import overlay_ego_road_on_image\n",
    "\n",
    "frame_id = \"062592\"\n",
    "ego_road_annotation = zod.read_ego_road_annotation(frame_id)\n",
    "image = plt.imread(zod.get_image_path(frame_id))\n",
    "image = overlay_ego_road_on_image(ego_road_annotation, image)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
