{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZodFrames & ZodSequences: an introduction\n",
    "This notebook aims to introduce the ZodFrames & ZodSequences classes, which are helper classes to interact with the Frames and Sequences subsets of Zenseact Open Dataset (ZOD). It will highlight some basic functionality that can be used to build dataloaders in various frameworks, for example PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the package\n",
    "from zod import ZodFrames, ZodSequences\n",
    "from zod.data_classes import LidarData\n",
    "import zod.constants as constants\n",
    "from zod.constants import Lidar, Anonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the class with the dataset root and version, version can be \"mini\" or \"full\"\n",
    "dataset_root = \"\"  # NOTE! Set this to the path to the dataset\n",
    "zod_frames = ZodFrames(dataset_root=dataset_root, version=\"mini\")\n",
    "zod_sequences = ZodSequences(dataset_root=dataset_root, version=\"mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training and validation split\n",
    "training_frames = zod_frames.get_split(constants.TRAIN)\n",
    "validation_frames = zod_frames.get_split(constants.VAL)\n",
    "\n",
    "# Print the number of training and validation frames\n",
    "print(f\"Number of training frames: {len(training_frames)}\")\n",
    "print(f\"Number of validation frames: {len(validation_frames)}\")\n",
    "\n",
    "# Print the number of training and validation sequences\n",
    "training_sequences = zod_sequences.get_split(constants.TRAIN)\n",
    "validation_sequences = zod_sequences.get_split(constants.VAL)\n",
    "print(f\"Number of training sequences: {len(training_sequences)}\")\n",
    "print(f\"Number of validation sequences: {len(validation_sequences)}\")\n",
    "\n",
    "# Print out the first 5 training frames\n",
    "print(\"The 5 first training frames have the ids:\", training_frames[:5])\n",
    "\n",
    "# Show the first training sequence\n",
    "print(\"The first training sequence has the id:\", training_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also get a frame by its id\n",
    "frame_from_id = zod_frames[\"009158\"]\n",
    "\n",
    "# We can also get it via the index\n",
    "frame_from_idx = zod_frames[9158]\n",
    "\n",
    "# The two frames should be the same\n",
    "assert frame_from_id.info == frame_from_idx.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the frame to get the ego-motion of the vehicle\n",
    "ego_motion = frame_from_id.ego_motion\n",
    "print(f\"Acceleration: {ego_motion.accelerations.shape}\")\n",
    "print(f\"Velocities: {ego_motion.velocities.shape}\")\n",
    "print(f\"Poses: {ego_motion.poses.shape}\")\n",
    "print(f\"Timestamps: {ego_motion.timestamps.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the ego-motion is a lightweight version of the oxts data\n",
    "oxts = frame_from_id.oxts\n",
    "print(f\"Acceleration: {oxts.accelerations.shape}\")\n",
    "print(f\"Velocities: {oxts.velocities.shape}\")\n",
    "print(f\"Poses: {oxts.poses.shape}\")\n",
    "print(f\"Timestamps: {oxts.timestamps.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the ZodFrames class yield a `ZodFrame` which acts a cache for the lightweight data (e.g., ego-motion, calibration, and metadata), but also holds an `info` attribute. This in turn holds all the paths to more heavyweight data (e.g., images and point clouds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lidar core-frame for this ZodFrame\n",
    "lidar_core_frame = frame_from_id.info.get_key_lidar_frame()\n",
    "print(lidar_core_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the lidar data\n",
    "pc: LidarData = lidar_core_frame.read()\n",
    "print(f\"Points: {pc.points.shape}\")  # x, y, z\n",
    "print(f\"Timestamps: {pc.timestamps.shape}\")\n",
    "print(f\"Intensity: {pc.intensity.shape}\")\n",
    "print(f\"Diode: {pc.diode_idx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also iterate over all point-clouds\n",
    "lidar_frames = frame_from_id.info.get_lidar_frames()\n",
    "for i, lidar_frame in enumerate(lidar_frames):\n",
    "    pc = lidar_frame.read()\n",
    "    print(f\"Lidar frame # {i}\")\n",
    "    print(f\"Points: {pc.points.shape}\")  # x, y, z\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the same for the sequences\n",
    "seq = zod_sequences[training_sequences[0]]\n",
    "\n",
    "# Get the lidar frames\n",
    "print(f\"Number of lidar frames: {len(seq.info.get_lidar_frames(lidar=Lidar.VELODYNE))}\")\n",
    "# We can also get the original camera frames\n",
    "print(\n",
    "    f\"Number of camera frames: {len(seq.info.get_camera_frames(anonymization=Anonymization.ORIGINAL))}\"\n",
    ")\n",
    "\n",
    "# Or see how long the sequence is\n",
    "print(f\"Timespan: {(seq.info.end_time - seq.info.start_time).total_seconds()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df42b3a4a30759cb35304eb034da59ecddf2d66284374157770c9d0349c836ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
